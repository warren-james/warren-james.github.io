[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Warren James, PhD",
    "section": "",
    "text": "I am a researcher interested in using a whole host of statistical methods to answer all sorts of interesting (not always) questions. The work I do is all in R and so I thought to save me time I could put some of this on a website somewhere that other people might also find useful.\nCurrently, I’m employed as part of the Epidemiology group, and the Biostatistics and Health Data Science Group as a research fellow where I use Electronic Health Care records to answer questions of clinical interest"
  },
  {
    "objectID": "blog/index.html",
    "href": "blog/index.html",
    "title": "Some things I wrote about things I find interesting",
    "section": "",
    "text": "Landing page for any blog posts I’ll make at some point. Basically, anything I do that I think may be of use to other people (and my presumably future smarter self) in the future will go here."
  },
  {
    "objectID": "about/index.html",
    "href": "about/index.html",
    "title": "About",
    "section": "",
    "text": "this would be a page where I talk about myself because I’m cool like that"
  },
  {
    "objectID": "supMat/2024_06_IdentifyingKeySystemComponents/identifyingKeyComponents.html#simulate-visit-data",
    "href": "supMat/2024_06_IdentifyingKeySystemComponents/identifyingKeyComponents.html#simulate-visit-data",
    "title": "VOICES_keyServiceComponents",
    "section": "Simulate visit data",
    "text": "Simulate visit data\nNow all the values are in the dataset, we can produce count data for the number of visits each patient had during the time they were in the study.\n\nDemonstration\nTo show that this function behaves in the expected way, I have generated two datasets using the bespoke nbinomProcess function and the built in rnbinom function to generate two datasets using the same parameters. The exposure time will be kept constant to allow for an easier comparison to be made with the true distribution.\n\n# set some parameters\nN &lt;- 1e6\nthisMu &lt;- 3.4\nthisSize &lt;- 10.3\n\n# generate data using the rnbinom() function\ndf_rnbinom &lt;- tibble(subj = 1:N, \n                     nEvents = rnbinom(N, thisSize, mu = thisMu), \n                     thisFunction = \"rnbinom\")\n\n# generate data using the nbinomProcess() function\ndf_nbinomProcess &lt;- tibble(subj = 1:N,\n                           thisFunction = \"nbinomProcess\") \ndf_nbinomProcess$nEvents &lt;- sapply(1:N, function(i){\n  nbinomProcess(thisMu, thisSize, 1)\n})\ndf_nbinomProcess$nEvents &lt;- sapply(1:N, function(i){\n  length(df_nbinomProcess$nEvents[[i]])\n})\n\n# create figure to compare \nrbind(df_rnbinom, df_nbinomProcess) %&gt;% \n  ggplot(aes(nEvents, fill = thisFunction)) + \n  geom_histogram(binwidth = 1, \n                 position = \"dodge\") + \n  geom_line(data = tibble(x = 0:max(c(df_rnbinom$nEvents, df_nbinomProcess$nEvents)), \n                          y = dnbinom(x, thisSize, mu = thisMu) * N),\n            aes(x, y), \n            inherit.aes = F) +\n  geom_point(data = tibble(x = 0:max(c(df_rnbinom$nEvents, df_nbinomProcess$nEvents)), \n                           y = dnbinom(x, thisSize, mu = thisMu) * N),\n             aes(x, y), \n             size = 3,\n             inherit.aes = F) +\n  scale_fill_flat()\n\n\n\n\n\n\n\n\nFrom the above, we can see that the functions produce very similar results that both match onto the true distribution with a high enough number of samples. The reason for the nbinomProcess function is to produce a number of events with time stamps to make data that looks similar to what would be available for analysis."
  },
  {
    "objectID": "supMat/2024_06_IdentifyingKeySystemComponents/identifyingKeyComponents.html#create-synthetic-dataset",
    "href": "supMat/2024_06_IdentifyingKeySystemComponents/identifyingKeyComponents.html#create-synthetic-dataset",
    "title": "VOICES_keyServiceComponents",
    "section": "Create synthetic dataset",
    "text": "Create synthetic dataset\n\n# generate a series of positive and negative events \n# For the purposes of this dataset, I've made it so that everyone has 3 \"negative\" events\ntoBind &lt;- t(sapply(1:nrow(df_patientData), function(i){\n  time &lt;- df_patientData$timeYears[i]\n  genVisits(3, df_patientData$mu[i], df_patientData$shape[i] * time, time)\n})) \n\n# bind the data and unnest the list columns \ndf_patientData &lt;- df_patientData %&gt;% \n  cbind(toBind) %&gt;% \n  unnest(c(posEvent, EventTime))"
  },
  {
    "objectID": "supMat/2024_06_IdentifyingKeySystemComponents/identifyingKeyComponents.html#format-dataset",
    "href": "supMat/2024_06_IdentifyingKeySystemComponents/identifyingKeyComponents.html#format-dataset",
    "title": "VOICES_keyServiceComponents",
    "section": "Format dataset",
    "text": "Format dataset\nNow we have the event times, we can make the dataset look a touch more realistic.\n\n# end Date of study to get index data for each patient\nendDate &lt;- as.Date(\"2020-10-31\") \n\n# function to convert between numbers and the data\nChangeTime &lt;- function(og_date, thisYears){\n  if(thisYears[1] &lt; 0){\n    sub &lt;- T\n    thisYears &lt;- abs(thisYears)\n  } else {\n    sub &lt;- F\n  }\n  \n  # sort year value\n  floorYears &lt;- floor(thisYears)\n\n  # sort month value\n  thisMonth &lt;- (thisYears - floorYears) * 12\n  floorMonth &lt;- floor(thisMonth)\n  \n  # sort day value\n  thisDay &lt;- thisMonth - floorMonth\n  thisDay &lt;- round(thisDay * 28)\n  \n  # have to do the months as days because it goes wonky with certain dates otherwise \n  if(sub){\n    og_date -(years(floorYears) + days(floorMonth * 28) + days(thisDay)) \n  } else {\n    og_date + (years(floorYears) + days(floorMonth * 28) + days(thisDay))   \n  }\n}\n\n# format the dataset to look more realistic\ndf_patientData &lt;- df_patientData %&gt;% \n  select(-c(Intercept, shape, iter, mu)) %&gt;%\n  mutate(across(c(AdviceandorLed:WaitTimeNewWithinWeek), ~ abs(.x) &gt; 0), \n         indexDate = ChangeTime(endDate, -timeYears), \n         eventDate = ChangeTime(indexDate, EventTime)) %&gt;% \n  select(subj, indexDate, Board, timeYears, everything(), -EventTime)\n\n# add in an mcon column which is based on whether the event was \"positive\"\n# NB: The \"Codes_X\" variables are defined in the markdown document which can be \n#     found in the github repository. \n#     They are the same as the codes seen in the readME file for the repository. \ndf_patientData$mcon &lt;- sapply(1:nrow(df_patientData), function(i){\n  if(df_patientData$posEvent[i]) {\n    sample(Codes_SI, 1)\n  } else {\n    sample(c(Codes_Cancer, Codes_CVD), 1)\n  }\n})\n\n# Add in some other codes\ndf_patientData$ocon &lt;- sapply(1:nrow(df_patientData), function(i){\n  nOthers &lt;- sample(0:5, 1)\n  if(df_patientData$posEvent[i]){\n    output &lt;- sample(c(Codes_SI, Codes_Cancer, Codes_CVD), nOthers)\n  } else {\n    output &lt;- sample(c(Codes_Cancer, Codes_CVD), nOthers)\n  }\n  paste(c(output, rep(\"NA\", 5 - nOthers)), collapse = \"|\")\n})\n\n# tidy up the dataset \ndf_patientData &lt;- df_patientData %&gt;% \n  separate(ocon, into = paste0(\"ocon\", c(1:5)), sep = \"[|]\")\n\n# show the dataset\nreactable(df_patientData)\n\n\n\n\n\nPlease note, the ICD-10 codes that don’t relate to Serious Infection were sample from two other lists regarding Cancer and Cardiovascular Disease so these probably aren’t the most clinically valid. The extra codes are simply there to give an impression of what the real data looks like."
  },
  {
    "objectID": "supMat/2024_06_IdentifyingKeySystemComponents/identifyingKeyComponents.html#run-model",
    "href": "supMat/2024_06_IdentifyingKeySystemComponents/identifyingKeyComponents.html#run-model",
    "title": "VOICES_keyServiceComponents",
    "section": "Run model",
    "text": "Run model\nThe model was fit using the brms library. All variables regarding the service components were entered as main effects. In the paper, additional parameters include Sex (deviation scaled), Age (median centered and decade scaled), Urban/Rural status (2 fold classification), and Scottish Index of Multiple Deprivation (as quintiles with 3 set as the baseline). Additionally, there was a random intercept for board of treatment to account for differences in base rates of Serious Infection. For this example, these haven’t been included. All coefficients regarding the service components (and the demographic features in the paper) were given a weakly informative prior of a student t distribution with a mean of 0, degrees of freedom of 3, and standard deviation of 1. A comparison between the prior predictions and posterior predictions can be seen by fitting the same model with the sample_prior argument set to \"only\".\n\nmy_prior &lt;- prior(student_t(3, 0, 1), class = \"b\")\n\n# A model that only samples the prior \n# I've commented this out because it doesn't need to be run here \n# but should you want to check the prior assumptions, this is the code you need\n# m_nbinomn_priorOnly &lt;- brm(\n#   SI_events | rate(timeYears) ~\n#     AdviceandorLed + CohortedClinic + JointParaClinic + \n#     LocalAAVpath + OwnDayCaseUnit + VascMDT + \n#     WaitTimeNewWithinWeek, \n#   data = df_modelData, \n#   family = negbinomial(), \n#   prior = my_prior,\n#   sample_prior = \"only\",\n#   chains = 1,\n#   iter = 4000, \n#   warmup = 3000,\n#   control = list(adapt_delta = .9)\n# )\n\nm_nbinom &lt;- brm(\n  SI_events | rate(timeYears) ~\n    AdviceandorLed + CohortedClinic + JointParaClinic + \n    LocalAAVpath + OwnDayCaseUnit + VascMDT + \n    WaitTimeNewWithinWeek, \n  data = df_modelData, \n  family = negbinomial(), \n  prior = my_prior, \n  chains = 1,\n  iter = 4000, \n  warmup = 2000,\n  control = list(adapt_delta = .9)\n)\n\nCompiling Stan program...\n\n\nStart sampling\n\n\n\nSAMPLING FOR MODEL 'anon_model' NOW (CHAIN 1).\nChain 1: \nChain 1: Gradient evaluation took 0.000848 seconds\nChain 1: 1000 transitions using 10 leapfrog steps per transition would take 8.48 seconds.\nChain 1: Adjust your expectations accordingly!\nChain 1: \nChain 1: \nChain 1: Iteration:    1 / 4000 [  0%]  (Warmup)\nChain 1: Iteration:  400 / 4000 [ 10%]  (Warmup)\nChain 1: Iteration:  800 / 4000 [ 20%]  (Warmup)\nChain 1: Iteration: 1200 / 4000 [ 30%]  (Warmup)\nChain 1: Iteration: 1600 / 4000 [ 40%]  (Warmup)\nChain 1: Iteration: 2000 / 4000 [ 50%]  (Warmup)\nChain 1: Iteration: 2001 / 4000 [ 50%]  (Sampling)\nChain 1: Iteration: 2400 / 4000 [ 60%]  (Sampling)\nChain 1: Iteration: 2800 / 4000 [ 70%]  (Sampling)\nChain 1: Iteration: 3200 / 4000 [ 80%]  (Sampling)\nChain 1: Iteration: 3600 / 4000 [ 90%]  (Sampling)\nChain 1: Iteration: 4000 / 4000 [100%]  (Sampling)\nChain 1: \nChain 1:  Elapsed Time: 7.768 seconds (Warm-up)\nChain 1:                7.393 seconds (Sampling)\nChain 1:                15.161 seconds (Total)\nChain 1: \n\nsummary(m_nbinom)\n\n Family: negbinomial \n  Links: mu = log; shape = identity \nFormula: SI_events | rate(timeYears) ~ AdviceandorLed + CohortedClinic + JointParaClinic + LocalAAVpath + OwnDayCaseUnit + VascMDT + WaitTimeNewWithinWeek \n   Data: df_modelData (Number of observations: 850) \n  Draws: 1 chains, each with iter = 4000; warmup = 2000; thin = 1;\n         total post-warmup draws = 2000\n\nPopulation-Level Effects: \n                          Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS\nIntercept                    -1.66      0.15    -1.95    -1.37 1.00     1750\nAdviceandorLedTRUE            0.10      0.18    -0.25     0.45 1.00     1436\nCohortedClinicTRUE           -0.15      0.09    -0.32     0.02 1.00     1600\nJointParaClinicTRUE           0.05      0.09    -0.14     0.21 1.00     2229\nLocalAAVpathTRUE             -0.13      0.10    -0.32     0.06 1.00     1728\nOwnDayCaseUnitTRUE            0.11      0.11    -0.10     0.32 1.00     1581\nVascMDTTRUE                  -0.14      0.17    -0.47     0.21 1.00     1562\nWaitTimeNewWithinWeekTRUE    -0.04      0.12    -0.29     0.21 1.00     1851\n                          Tail_ESS\nIntercept                     1593\nAdviceandorLedTRUE            1297\nCohortedClinicTRUE            1514\nJointParaClinicTRUE           1451\nLocalAAVpathTRUE              1405\nOwnDayCaseUnitTRUE            1630\nVascMDTTRUE                   1090\nWaitTimeNewWithinWeekTRUE     1606\n\nFamily Specific Parameters: \n      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nshape     0.16      0.02     0.13     0.20 1.00     2058     1515\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\n\nAbove, the model results can be show in terms of the coefficient values. The first thing to notice is that the Credibility Intervals are more narrow than those of in the paper, but this is primarily due to there being less noise in the estimates associated with patients having varying demographic features and no noise added due to random effects. In essence, this simulated data only allows access to service components to vary with all other features being the same. Generally, the results look very similar to those in the paper despite the limitations."
  },
  {
    "objectID": "supMat/2024_06_IdentifyingKeySystemComponents/identifyingKeyComponents.html#show-model-results",
    "href": "supMat/2024_06_IdentifyingKeySystemComponents/identifyingKeyComponents.html#show-model-results",
    "title": "VOICES_keyServiceComponents",
    "section": "Show model results",
    "text": "Show model results\nSimply looking at the summary isn’t always the easiest way to understand these results, so below I’ve created a few plots to demonstrate make things clearer. The first thing to do is get the posterior draws.\n\npost_nbinom &lt;- m_nbinom %&gt;% \n  as.matrix() %&gt;% \n  as_tibble() %&gt;% \n  select(-c(lp__, lprior)) \n\n\nPlotting results\n\nRaw coefficients\nThis figure shows the raw coefficients on a log scale. With the expection of the Intercept, all values can be compared to the 0 line in order to get a sense for the direction of the effect.\n\n\n\n\n\n\n\n\n\n\n\nIncident Rate Ratios\nThis figure shows the Incident Rate Ratio for each service component. These values correspond to the ratio of the rate between a service component being present and not being present. Values greater than one show an increase in the rate, while values lower than one show a decrease in the rate.\n\n\n\n\n\n\n\n\n\n\n\nResults as rates\nThis figure shows the results as rate values. This way compares how the presence of different service components was associated with changes in the yearly rate of Serious Infection. The vertical line represents the mean Intercept rate with the shaded region showing the 95% credibility interval. Please note, this doesn’t show the range of predicted counts, but the uncertainty in the estimate for the mean parameter (i.e., the mean rate of events in these data)."
  },
  {
    "objectID": "supMat/2024_06_IdentifyingKeySystemComponents/identifyingKeyComponents.html#expected-number-of-events-over-time",
    "href": "supMat/2024_06_IdentifyingKeySystemComponents/identifyingKeyComponents.html#expected-number-of-events-over-time",
    "title": "VOICES_keyServiceComponents",
    "section": "Expected number of events over time",
    "text": "Expected number of events over time\nThis plot shows the total number of expected events over time in the absence of any of the service components (in grey). Each facet shows how this number of events could be expected to change this count compared to having no other service components. The larger shaded region shows where 95% of the data would be expected to lie in a negative binomial distribution using the point estimates from the model outputs. The solid line shows the mean number of events to be expected given the parameter values. The shaded region between the dashed lines shows the 95% credibility interval around the estimate for the mean value.\n\n# poorly named function... please don't do this, make useful function names\n# this function is also really specific to this problem, so it would need to be adapted \n# for any other model/dataset\n# Using the rnbinom() function is susceptible to the upper and lower bounds moving about due to \n# the nature of these data being integers... \nmakePlot &lt;- function(thisModel, minTime, maxTime, res = .02) {\n  post &lt;- thisModel %&gt;% as.matrix() %&gt;% \n    as_tibble() %&gt;% \n    select(-c(lprior, lp__)) %&gt;% \n    mutate(across(2:(ncol(.) - 1), ~ .x + b_Intercept),\n           across(1:(ncol(.) - 1), ~ exp(.x))) %&gt;% \n    gather(1:(ncol(.)), \n           key = \"param\", \n           value = \"coef\") %&gt;% \n    group_by(param) %&gt;% \n    mean_hdci(coef)  %&gt;% \n    expand_grid(time = seq(minTime, maxTime, res)) %&gt;% \n    group_by(param) %&gt;% \n    mutate(iter = row_number()) %&gt;% \n    select(iter, everything()) %&gt;% \n    ungroup() \n  \n  quantile_data &lt;- post %&gt;% \n    select(param, coef, time) %&gt;% \n    spread(param, coef) %&gt;% \n    gather(2:(ncol(.) - 1), \n           key = \"param\", \n           value = \"mu\") %&gt;% \n    mutate(param = str_remove(param, \"b_\"), \n           param = str_remove(param, \"TRUE\"),\n           q.5 = qnbinom(.5, shape * time, mu = mu * time),\n           q.975 = qnbinom(.975, shape * time, mu = mu * time),\n           q.025 = qnbinom(.025, shape * time, mu = mu * time))\n  \n  mu_post &lt;- post %&gt;% \n    select(-c(.width, .point, .interval)) %&gt;%  \n    filter(!param %in% c(\"shape\", \"b_Intercept\")) %&gt;% \n    left_join(post %&gt;%\n                filter(param == \"shape\") %&gt;% \n                select(iter, coef) %&gt;% \n                rename(shape = coef)) %&gt;% \n    mutate(param = str_remove(param, \"b_\"), \n           param = str_remove(param, \"TRUE\"),\n           q.5_med = qnbinom(.5, shape * time, mu = coef * time),\n           q.5_upr = qnbinom(.5, shape * time, mu = .upper * time),\n           q.5_lwr = qnbinom(.5, shape * time, mu = .lower * time)) \n  \n  quantile_data[quantile_data$param != \"Intercept\",] %&gt;% \n    ggplot(aes(time, q.5, colour = param)) + \n    geom_path(data = quantile_data[quantile_data$param == \"Intercept\",] %&gt;% \n                select(-param), \n              aes(time, q.5),\n              colour = \"black\") +\n    geom_ribbon(data = quantile_data[quantile_data$param == \"Intercept\",] %&gt;% \n                select(-param), \n                aes(ymin = q.025, ymax = q.975), \n                fill = \"black\", \n                colour = \"transparent\",\n                alpha = .1) + \n    geom_path() + \n    geom_ribbon(aes(ymin = q.025, ymax = q.975, \n                    fill = param), \n                colour = \"transparent\",\n                alpha = .2) +\n    geom_ribbon(data = mu_post,\n                aes(x = time,\n                    ymin = q.5_lwr - .2, ymax = q.5_upr + .2,\n                    y = q.5_med,\n                    fill = param),\n                alpha = .2,\n                linetype = \"longdash\") +\n    scale_x_continuous(\"Time since Index Date\") + \n    scale_y_continuous(\"Estimated total number of Serious Infections\") +\n    facet_wrap(~param) +\n    theme(legend.position = \"bottom\", \n          panel.grid.major.y = element_line())\n  \n  # return(post)\n}\n\nmakePlot(m_nbinom, .1, 24) \n\nJoining with `by = join_by(iter)`"
  },
  {
    "objectID": "supMat/index.html",
    "href": "supMat/index.html",
    "title": "Supplementary Materials",
    "section": "",
    "text": "VOICES: Identidying Key Service Components\n\n\n\n\n\n\n\n\n\n\n\nJul 1, 2024\n\n\nWarren James\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "supMat/2024_06_IdentifyingKeySystemComponents/index.html#simulate-visit-data",
    "href": "supMat/2024_06_IdentifyingKeySystemComponents/index.html#simulate-visit-data",
    "title": "VOICES: Identidying Key Service Components",
    "section": "Simulate visit data",
    "text": "Simulate visit data\nNow all the values are in the dataset, we can produce count data for the number of visits each patient had during the time they were in the study.\n\nDemonstration\nTo show that this function behaves in the expected way, I have generated two datasets using the bespoke nbinomProcess function and the built in rnbinom function to generate two datasets using the same parameters. The exposure time will be kept constant to allow for an easier comparison to be made with the true distribution.\n\n# set some parameters\nN &lt;- 1e6\nthisMu &lt;- 3.4\nthisSize &lt;- 10.3\n\n# generate data using the rnbinom() function\ndf_rnbinom &lt;- tibble(subj = 1:N, \n                     nEvents = rnbinom(N, thisSize, mu = thisMu), \n                     thisFunction = \"rnbinom\")\n\n# generate data using the nbinomProcess() function\ndf_nbinomProcess &lt;- tibble(subj = 1:N,\n                           thisFunction = \"nbinomProcess\") \ndf_nbinomProcess$nEvents &lt;- sapply(1:N, function(i){\n  nbinomProcess(thisMu, thisSize, 1)\n})\ndf_nbinomProcess$nEvents &lt;- sapply(1:N, function(i){\n  length(df_nbinomProcess$nEvents[[i]])\n})\n\n# create figure to compare \nrbind(df_rnbinom, df_nbinomProcess) %&gt;% \n  ggplot(aes(nEvents, fill = thisFunction)) + \n  geom_histogram(binwidth = 1, \n                 position = \"dodge\") + \n  geom_line(data = tibble(x = 0:max(c(df_rnbinom$nEvents, df_nbinomProcess$nEvents)), \n                          y = dnbinom(x, thisSize, mu = thisMu) * N),\n            aes(x, y), \n            inherit.aes = F) +\n  geom_point(data = tibble(x = 0:max(c(df_rnbinom$nEvents, df_nbinomProcess$nEvents)), \n                           y = dnbinom(x, thisSize, mu = thisMu) * N),\n             aes(x, y), \n             size = 3,\n             inherit.aes = F) +\n  scale_fill_flat()\n\n\n\n\n\n\n\n\nFrom the above, we can see that the functions produce very similar results that both match onto the true distribution with a high enough number of samples. The reason for the nbinomProcess function is to produce a number of events with time stamps to make data that looks similar to what would be available for analysis."
  },
  {
    "objectID": "supMat/2024_06_IdentifyingKeySystemComponents/index.html#create-synthetic-dataset",
    "href": "supMat/2024_06_IdentifyingKeySystemComponents/index.html#create-synthetic-dataset",
    "title": "VOICES: Identidying Key Service Components",
    "section": "Create synthetic dataset",
    "text": "Create synthetic dataset\n\n# generate a series of positive and negative events \n# For the purposes of this dataset, I've made it so that everyone has 3 \"negative\" events\ntoBind &lt;- t(sapply(1:nrow(df_patientData), function(i){\n  time &lt;- df_patientData$timeYears[i]\n  genVisits(3, df_patientData$mu[i], df_patientData$shape[i] * time, time)\n})) \n\n# bind the data and unnest the list columns \ndf_patientData &lt;- df_patientData %&gt;% \n  cbind(toBind) %&gt;% \n  unnest(c(posEvent, EventTime))"
  },
  {
    "objectID": "supMat/2024_06_IdentifyingKeySystemComponents/index.html#format-dataset",
    "href": "supMat/2024_06_IdentifyingKeySystemComponents/index.html#format-dataset",
    "title": "VOICES: Identidying Key Service Components",
    "section": "Format dataset",
    "text": "Format dataset\nNow we have the event times, we can make the dataset look a touch more realistic.\n\n# end Date of study to get index data for each patient\nendDate &lt;- as.Date(\"2020-10-31\") \n\n# function to convert between numbers and the data\nChangeTime &lt;- function(og_date, thisYears){\n  if(thisYears[1] &lt; 0){\n    sub &lt;- T\n    thisYears &lt;- abs(thisYears)\n  } else {\n    sub &lt;- F\n  }\n  \n  # sort year value\n  floorYears &lt;- floor(thisYears)\n\n  # sort month value\n  thisMonth &lt;- (thisYears - floorYears) * 12\n  floorMonth &lt;- floor(thisMonth)\n  \n  # sort day value\n  thisDay &lt;- thisMonth - floorMonth\n  thisDay &lt;- round(thisDay * 28)\n  \n  # have to do the months as days because it goes wonky with certain dates otherwise \n  if(sub){\n    og_date -(years(floorYears) + days(floorMonth * 28) + days(thisDay)) \n  } else {\n    og_date + (years(floorYears) + days(floorMonth * 28) + days(thisDay))   \n  }\n}\n\n# format the dataset to look more realistic\ndf_patientData &lt;- df_patientData %&gt;% \n  select(-c(Intercept, shape, iter, mu)) %&gt;%\n  mutate(across(c(AdviceandorLed:WaitTimeNewWithinWeek), ~ abs(.x) &gt; 0), \n         indexDate = ChangeTime(endDate, -timeYears), \n         eventDate = ChangeTime(indexDate, EventTime)) %&gt;% \n  select(subj, indexDate, Board, timeYears, everything(), -EventTime)\n\n# add in an mcon column which is based on whether the event was \"positive\"\n# NB: The \"Codes_X\" variables are defined in the markdown document which can be \n#     found in the github repository. \n#     They are the same as the codes seen in the readME file for the repository. \ndf_patientData$mcon &lt;- sapply(1:nrow(df_patientData), function(i){\n  if(df_patientData$posEvent[i]) {\n    sample(Codes_SI, 1)\n  } else {\n    sample(c(Codes_Cancer, Codes_CVD), 1)\n  }\n})\n\n# Add in some other codes\ndf_patientData$ocon &lt;- sapply(1:nrow(df_patientData), function(i){\n  nOthers &lt;- sample(0:5, 1)\n  if(df_patientData$posEvent[i]){\n    output &lt;- sample(c(Codes_SI, Codes_Cancer, Codes_CVD), nOthers)\n  } else {\n    output &lt;- sample(c(Codes_Cancer, Codes_CVD), nOthers)\n  }\n  paste(c(output, rep(\"NA\", 5 - nOthers)), collapse = \"|\")\n})\n\n# tidy up the dataset \ndf_patientData &lt;- df_patientData %&gt;% \n  separate(ocon, into = paste0(\"ocon\", c(1:5)), sep = \"[|]\")\n\n# show the dataset\nreactable(df_patientData)\n\n\n\n\n\nPlease note, the ICD-10 codes that don’t relate to Serious Infection were sample from two other lists regarding Cancer and Cardiovascular Disease so these probably aren’t the most clinically valid. The extra codes are simply there to give an impression of what the real data looks like."
  },
  {
    "objectID": "supMat/2024_06_IdentifyingKeySystemComponents/index.html#run-model",
    "href": "supMat/2024_06_IdentifyingKeySystemComponents/index.html#run-model",
    "title": "VOICES: Identidying Key Service Components",
    "section": "Run model",
    "text": "Run model\nThe model was fit using the brms library. All variables regarding the service components were entered as main effects. In the paper, additional parameters include Sex (deviation scaled), Age (median centered and decade scaled), Urban/Rural status (2 fold classification), and Scottish Index of Multiple Deprivation (as quintiles with 3 set as the baseline). Additionally, there was a random intercept for board of treatment to account for differences in base rates of Serious Infection. For this example, these haven’t been included. All coefficients regarding the service components (and the demographic features in the paper) were given a weakly informative prior of a student t distribution with a mean of 0, degrees of freedom of 3, and standard deviation of 1. A comparison between the prior predictions and posterior predictions can be seen by fitting the same model with the sample_prior argument set to \"only\".\n\nmy_prior &lt;- prior(student_t(3, 0, 1), class = \"b\")\n\n# A model that only samples the prior \n# I've commented this out because it doesn't need to be run here \n# but should you want to check the prior assumptions, this is the code you need\n# m_nbinomn_priorOnly &lt;- brm(\n#   SI_events | rate(timeYears) ~\n#     AdviceandorLed + CohortedClinic + JointParaClinic + \n#     LocalAAVpath + OwnDayCaseUnit + VascMDT + \n#     WaitTimeNewWithinWeek, \n#   data = df_modelData, \n#   family = negbinomial(), \n#   prior = my_prior,\n#   sample_prior = \"only\",\n#   chains = 1,\n#   iter = 4000, \n#   warmup = 3000,\n#   control = list(adapt_delta = .9)\n# )\n\nm_nbinom &lt;- brm(\n  SI_events | rate(timeYears) ~\n    AdviceandorLed + CohortedClinic + JointParaClinic + \n    LocalAAVpath + OwnDayCaseUnit + VascMDT + \n    WaitTimeNewWithinWeek, \n  data = df_modelData, \n  family = negbinomial(), \n  prior = my_prior, \n  chains = 1,\n  iter = 4000, \n  warmup = 2000,\n  control = list(adapt_delta = .9)\n)\n\nCompiling Stan program...\n\n\nStart sampling\n\n\n\nSAMPLING FOR MODEL 'anon_model' NOW (CHAIN 1).\nChain 1: \nChain 1: Gradient evaluation took 0.00048 seconds\nChain 1: 1000 transitions using 10 leapfrog steps per transition would take 4.8 seconds.\nChain 1: Adjust your expectations accordingly!\nChain 1: \nChain 1: \nChain 1: Iteration:    1 / 4000 [  0%]  (Warmup)\nChain 1: Iteration:  400 / 4000 [ 10%]  (Warmup)\nChain 1: Iteration:  800 / 4000 [ 20%]  (Warmup)\nChain 1: Iteration: 1200 / 4000 [ 30%]  (Warmup)\nChain 1: Iteration: 1600 / 4000 [ 40%]  (Warmup)\nChain 1: Iteration: 2000 / 4000 [ 50%]  (Warmup)\nChain 1: Iteration: 2001 / 4000 [ 50%]  (Sampling)\nChain 1: Iteration: 2400 / 4000 [ 60%]  (Sampling)\nChain 1: Iteration: 2800 / 4000 [ 70%]  (Sampling)\nChain 1: Iteration: 3200 / 4000 [ 80%]  (Sampling)\nChain 1: Iteration: 3600 / 4000 [ 90%]  (Sampling)\nChain 1: Iteration: 4000 / 4000 [100%]  (Sampling)\nChain 1: \nChain 1:  Elapsed Time: 8.195 seconds (Warm-up)\nChain 1:                19.736 seconds (Sampling)\nChain 1:                27.931 seconds (Total)\nChain 1: \n\nsummary(m_nbinom)\n\n Family: negbinomial \n  Links: mu = log; shape = identity \nFormula: SI_events | rate(timeYears) ~ AdviceandorLed + CohortedClinic + JointParaClinic + LocalAAVpath + OwnDayCaseUnit + VascMDT + WaitTimeNewWithinWeek \n   Data: df_modelData (Number of observations: 850) \n  Draws: 1 chains, each with iter = 4000; warmup = 2000; thin = 1;\n         total post-warmup draws = 2000\n\nPopulation-Level Effects: \n                          Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS\nIntercept                    -1.66      0.15    -1.95    -1.37 1.00     1750\nAdviceandorLedTRUE            0.10      0.18    -0.25     0.45 1.00     1436\nCohortedClinicTRUE           -0.15      0.09    -0.32     0.02 1.00     1600\nJointParaClinicTRUE           0.05      0.09    -0.14     0.21 1.00     2229\nLocalAAVpathTRUE             -0.13      0.10    -0.32     0.06 1.00     1728\nOwnDayCaseUnitTRUE            0.11      0.11    -0.10     0.32 1.00     1581\nVascMDTTRUE                  -0.14      0.17    -0.47     0.21 1.00     1562\nWaitTimeNewWithinWeekTRUE    -0.04      0.12    -0.29     0.21 1.00     1851\n                          Tail_ESS\nIntercept                     1593\nAdviceandorLedTRUE            1297\nCohortedClinicTRUE            1514\nJointParaClinicTRUE           1451\nLocalAAVpathTRUE              1405\nOwnDayCaseUnitTRUE            1630\nVascMDTTRUE                   1090\nWaitTimeNewWithinWeekTRUE     1606\n\nFamily Specific Parameters: \n      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nshape     0.16      0.02     0.13     0.20 1.00     2058     1515\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\n\nAbove, the model results can be show in terms of the coefficient values. The first thing to notice is that the Credibility Intervals are more narrow than those of in the paper, but this is primarily due to there being less noise in the estimates associated with patients having varying demographic features and no noise added due to random effects. In essence, this simulated data only allows access to service components to vary with all other features being the same. Generally, the results look very similar to those in the paper despite the limitations."
  },
  {
    "objectID": "supMat/2024_06_IdentifyingKeySystemComponents/index.html#show-model-results",
    "href": "supMat/2024_06_IdentifyingKeySystemComponents/index.html#show-model-results",
    "title": "VOICES: Identidying Key Service Components",
    "section": "Show model results",
    "text": "Show model results\nSimply looking at the summary isn’t always the easiest way to understand these results, so below I’ve created a few plots to demonstrate make things clearer. The first thing to do is get the posterior draws.\n\npost_nbinom &lt;- m_nbinom %&gt;% \n  as.matrix() %&gt;% \n  as_tibble() %&gt;% \n  select(-c(lp__, lprior)) \n\n\nPlotting results\n\nRaw coefficients\nThis figure shows the raw coefficients on a log scale. With the expection of the Intercept, all values can be compared to the 0 line in order to get a sense for the direction of the effect.\n\n\n\n\n\n\n\n\n\n\n\nIncident Rate Ratios\nThis figure shows the Incident Rate Ratio for each service component. These values correspond to the ratio of the rate between a service component being present and not being present. Values greater than one show an increase in the rate, while values lower than one show a decrease in the rate.\n\n\n\n\n\n\n\n\n\n\n\nResults as rates\nThis figure shows the results as rate values. This way compares how the presence of different service components was associated with changes in the yearly rate of Serious Infection. The vertical line represents the mean Intercept rate with the shaded region showing the 95% credibility interval. Please note, this doesn’t show the range of predicted counts, but the uncertainty in the estimate for the mean parameter (i.e., the mean rate of events in these data)."
  },
  {
    "objectID": "supMat/2024_06_IdentifyingKeySystemComponents/index.html#expected-number-of-events-over-time",
    "href": "supMat/2024_06_IdentifyingKeySystemComponents/index.html#expected-number-of-events-over-time",
    "title": "VOICES: Identidying Key Service Components",
    "section": "Expected number of events over time",
    "text": "Expected number of events over time\nThis plot shows the total number of expected events over time in the absence of any of the service components (in grey). Each facet shows how this number of events could be expected to change this count compared to having no other service components. The larger shaded region shows where 95% of the data would be expected to lie in a negative binomial distribution using the point estimates from the model outputs. The solid line shows the mean number of events to be expected given the parameter values. The shaded region between the dashed lines shows the 95% credibility interval around the estimate for the mean value.\n\n# poorly named function... please don't do this, make useful function names\n# this function is also really specific to this problem, so it would need to be adapted \n# for any other model/dataset\n# Using the rnbinom() function is susceptible to the upper and lower bounds moving about due to \n# the nature of these data being integers... \nmakePlot &lt;- function(thisModel, minTime, maxTime, res = .02) {\n  post &lt;- thisModel %&gt;% as.matrix() %&gt;% \n    as_tibble() %&gt;% \n    select(-c(lprior, lp__)) %&gt;% \n    mutate(across(2:(ncol(.) - 1), ~ .x + b_Intercept),\n           across(1:(ncol(.) - 1), ~ exp(.x))) %&gt;% \n    gather(1:(ncol(.)), \n           key = \"param\", \n           value = \"coef\") %&gt;% \n    group_by(param) %&gt;% \n    mean_hdci(coef)  %&gt;% \n    expand_grid(time = seq(minTime, maxTime, res)) %&gt;% \n    group_by(param) %&gt;% \n    mutate(iter = row_number()) %&gt;% \n    select(iter, everything()) %&gt;% \n    ungroup() \n  \n  quantile_data &lt;- post %&gt;% \n    select(param, coef, time) %&gt;% \n    spread(param, coef) %&gt;% \n    gather(2:(ncol(.) - 1), \n           key = \"param\", \n           value = \"mu\") %&gt;% \n    mutate(param = str_remove(param, \"b_\"), \n           param = str_remove(param, \"TRUE\"),\n           q.5 = qnbinom(.5, shape * time, mu = mu * time),\n           q.975 = qnbinom(.975, shape * time, mu = mu * time),\n           q.025 = qnbinom(.025, shape * time, mu = mu * time))\n  \n  mu_post &lt;- post %&gt;% \n    select(-c(.width, .point, .interval)) %&gt;%  \n    filter(!param %in% c(\"shape\", \"b_Intercept\")) %&gt;% \n    left_join(post %&gt;%\n                filter(param == \"shape\") %&gt;% \n                select(iter, coef) %&gt;% \n                rename(shape = coef)) %&gt;% \n    mutate(param = str_remove(param, \"b_\"), \n           param = str_remove(param, \"TRUE\"),\n           q.5_med = qnbinom(.5, shape * time, mu = coef * time),\n           q.5_upr = qnbinom(.5, shape * time, mu = .upper * time),\n           q.5_lwr = qnbinom(.5, shape * time, mu = .lower * time)) \n  \n  quantile_data[quantile_data$param != \"Intercept\",] %&gt;% \n    ggplot(aes(time, q.5, colour = param)) + \n    geom_path(data = quantile_data[quantile_data$param == \"Intercept\",] %&gt;% \n                select(-param), \n              aes(time, q.5),\n              colour = \"black\") +\n    geom_ribbon(data = quantile_data[quantile_data$param == \"Intercept\",] %&gt;% \n                select(-param), \n                aes(ymin = q.025, ymax = q.975), \n                fill = \"black\", \n                colour = \"transparent\",\n                alpha = .1) + \n    geom_path() + \n    geom_ribbon(aes(ymin = q.025, ymax = q.975, \n                    fill = param), \n                colour = \"transparent\",\n                alpha = .2) +\n    geom_ribbon(data = mu_post,\n                aes(x = time,\n                    ymin = q.5_lwr - .2, ymax = q.5_upr + .2,\n                    y = q.5_med,\n                    fill = param),\n                alpha = .2,\n                linetype = \"longdash\") +\n    scale_x_continuous(\"Time since Index Date\") + \n    scale_y_continuous(\"Estimated total number of Serious Infections\") +\n    facet_wrap(~param) +\n    theme(legend.position = \"bottom\", \n          panel.grid.major.y = element_line())\n  \n  # return(post)\n}\n\nmakePlot(m_nbinom, .1, 24) \n\nJoining with `by = join_by(iter)`"
  }
]